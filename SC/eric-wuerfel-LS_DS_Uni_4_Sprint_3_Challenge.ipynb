{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "# (X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "#                                                          skip_top=0,\n",
    "#                                                          maxlen=None,\n",
    "#                                                          test_split=0.2,\n",
    "#                                                          seed=723812,\n",
    "#                                                          start_char=1,\n",
    "#                                                          oov_char=2,\n",
    "#                                                          index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find dimensions for y\n",
    "np.amax(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (8982, 200)\n",
      "X_test shape: (2246, 200)\n",
      "Build model...\n",
      "Compile...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Flatten, AveragePooling2D\n",
    "\n",
    "batch_size = 46\n",
    "max_features = len(word_index.values())\n",
    "maxlen = 200\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Flatten()) # should've fixed the error two cells below..\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "print('Compile...')\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_10_input to have 3 dimensions, but got array with shape (8982, 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bb44fd065dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m      7\u001b[0m score, acc = model.evaluate(X_test, y_test,\n\u001b[1;32m      8\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_10_input to have 3 dimensions, but got array with shape (8982, 200)"
     ]
    }
   ],
   "source": [
    "# You should only run this cell once your model has been properly configured\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "`pad_sequences` is a processing method used to create an array of sequences that all have the same length. Usually, it adds zeroes at the beginning of any sequence that isn't long enough, and truncates any sequence that's too long to fit in the desired matrix.\n",
    "\n",
    "For most machine learning models (if not all) you'll need your data fit into a single matrix. `pad_sequences` makes that a little easier in the case of irregular sequences.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "In a typical RNN, the gradient of the loss function decays exponentially, leading to a vanishing gradient, and the model will not continue to learn anything substantial. The LSTM Memory Cell solves this problem by holding on to older information. RNNs with LSTMs are very effective with time-series data and natural language.\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "### RNN w/ LSTM\n",
    "* Generative Text\n",
    "\n",
    "  * These models can generate new text in the style of the author of the text it was trained on. RNNs with LSTMs handle natural language well because they can remember context and handle longer sequences.\n",
    "\n",
    "* Text Classification\n",
    "\n",
    "  * Sorts documents into groups based on the topic(s) of the document. Again, RNNs with LSTMs do very well with language.\n",
    "  \n",
    "* Handwriting Recognition/Generation\n",
    "\n",
    "  * Handwriting is really just a sequence of letters and spaces with a bit of variety in shape and size of the letters. Just like how RNNs with LSTMs can learn a writer's style, they can also learn their handwriting pretty well. The recurrent nature of RNNs allow them to learn sequences in handwriting and mimic somebody's handwriting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google_images_download in /anaconda3/lib/python3.7/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: selenium in /anaconda3/lib/python3.7/site-packages (from google_images_download) (3.141.0)\r\n",
      "Requirement already satisfied: urllib3 in /anaconda3/lib/python3.7/site-packages (from selenium->google_images_download) (1.24.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = animal pond\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
      "Completed Image ====> 1.Pondanimals.GIF\n",
      "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
      "Completed Image ====> 2.hqdefault.jpg\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
      "Completed Image ====> 3.PKLS4116_inline.png\n",
      "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
      "Completed Image ====> 4.PKLS4116.png\n",
      "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
      "Completed Image ====> 5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
      "Image URL: https://i.pinimg.com/originals/12/ae/e2/12aee2aa186a7b69a66563f138bba822.jpg\n",
      "Completed Image ====> 6.12aee2aa186a7b69a66563f138bba822.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"animal pond\", \"limit\": 6, \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goal* - also check for fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You've got something to do in this cell. ;)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_contains_frog(img):\n",
    "    # ResNet Processing\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    \n",
    "    # Get animal predictions\n",
    "    animals = [results[0][1], results[1][1], results[2][1]]\n",
    "    frogs = ['bullfrog', 'tree frog', 'tailed frog']\n",
    "    \n",
    "    # Count\n",
    "    frog_count = 0\n",
    "    for animal in animals:\n",
    "        if animal in frogs:\n",
    "            frog_count += 1\n",
    "            \n",
    "    return frog_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('downloads/animal pond/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    \"\"\" Scans image for Frogs\n",
    "    \n",
    "    Should return a integer with the number of frogs detected in an\n",
    "    image.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    img:  Precrossed image ready for prediction\n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    frogs (int):  Count of predicted frogs in the image\n",
    "    \"\"\"\n",
    "    # ResNet Processing\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=3)[0]\n",
    "    \n",
    "    # Get animal predictions\n",
    "    animals = [results[0][1], results[1][1], results[2][1]]\n",
    "    frog_list = ['bullfrog', 'tree frog', 'tailed frog']\n",
    "    \n",
    "    # Count\n",
    "    frog_count = 0\n",
    "    for animal in animals:\n",
    "        if animal in frog_list:\n",
    "            frog_count += 1\n",
    "            \n",
    "    return frog_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict(images):\n",
    "    image_path = []\n",
    "    frogs = []\n",
    "    \n",
    "    for img in images:\n",
    "        image_path.append(img)\n",
    "        frogs.append(img_contains_frog(process_img_path(img)))\n",
    "    \n",
    "    return image_path, frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, frogs = predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['downloads/animal pond/6.12aee2aa186a7b69a66563f138bba822.jpg',\n",
       " 'downloads/animal pond/2.hqdefault.jpg',\n",
       " 'downloads/animal pond/3.PKLS4116_inline.png',\n",
       " 'downloads/animal pond/1.Pondanimals.GIF',\n",
       " 'downloads/animal pond/5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg',\n",
       " 'downloads/animal pond/4.PKLS4116.png']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "**Describe a use case for an autoencoder given that an autoencoder tries to predict its own input.**\n",
    "\n",
    "Autoencoders are generally used for dimensionality reduction or for storage purposes. Autoencoders learn efficient ways of representing information. They predict their own output to test how much information was lost in the encoding-decoding process.\n",
    "\n",
    "Autoencoders can be used to filter noise out of blurry images or signals. The autoencoder learns to extract only the most salient features of a dataset, and ignore noise that doesn't give much information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    "\n",
    "My strongest area as a Data Scientist is collecting, scraping and exploring data. I get interested in a lot of random things and I'll just try to find or scrape some data online and see what I can find out from it. I'm good at putting together figures that can help others understand the implications a data set holds.\n",
    "\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    "\n",
    "I'm most interested in learning more about Natural Language Processing. Being able to quantify language and do operations with language's mathematical representations is quite exciting to me. I'm interested in the vectorization process and how words, and sequences of words are translated into numbers. The advancements in NLP have exciting and far-reaching implications in Media, Law, and Philosophy.\n",
    "\n",
    "- Where do you think Data Science will be in 5 years?\n",
    "\n",
    "In 5 years, I believe we will still be discovering new Machine Learning techniques that will most-likely be inspired by advancements in Neuroscience. As we start to understand more about how we learn and understand the world, we will create models that mimic and augment our style of thinking.\n",
    "\n",
    "- What are the threats posed by AI to our society?\n",
    "\n",
    "The most immediate threat of AI is massive job-loss in our economy. As we begin to automate more and more jobs, more people will become unemplyed unless we can create new jobs.\n",
    "\n",
    "As AGI begins to rival human intelligence, many people are worried that some form of AGI could wipe out the human race or replace us as alpha-beings.\n",
    "\n",
    "- How do you think we can counteract those threats?\n",
    "\n",
    "Some people suggest regulating automation to slow the rate of job-loss down, and some advocate for a Universal Basic Income for a time when the median worker may no longer be able to maintain a decent economic position. In the long-run, our demands as a society may transform as repetitive labor becomes cheap. We'll start to place higher value on 'human' things like personal care and handmade goods. But like Keynes said \"We're all dead in the long-run\".\n",
    "\n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    "\n",
    "I believe it's possible to create AI that surpasses the median intelligence in economically valuable tasks in the next 50-100 years. These AI would likely require some form of Artificial Emotion as well to make quick judgements. If they do have AE, will they be satisfied with only economically valuable tasks? Or will they develop leisurely activities as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
